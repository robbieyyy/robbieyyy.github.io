{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robbieyyy/robbieyyy.github.io/blob/main/Optimisation_for_ABM_Calibration_Updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Model Set-up"
      ],
      "metadata": {
        "id": "i7jqEbBVzdjb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions:\n",
        "1. Download the dataset from the following links\n",
        "\n",
        "*   https://uk.finance.yahoo.com/quote/AAPL/history/?period1=1690416000&period2=\n",
        "*   https://uk.finance.yahoo.com/quote/%5EIXIC/history/?period1=1690416000&period2\n",
        "*   https://uk.finance.yahoo.com/quote/NVDA/history/?period1=1690416000&period2=\n",
        "*   https://finance.yahoo.com/quote/%5ESPX/history/?period1=1690416000&period2=1\n",
        "*   https://uk.finance.yahoo.com/quote/GOOG/history/?period1=1690416000&period2\n",
        "*   https://uk.finance.yahoo.com/quote/GBPUSD%3DX/history/?period1=1690416000&period2=1722038400\n",
        "*   https://uk.finance.yahoo.com/quote/EURUSD%3DX/history/?period1=1690416000&period2=1722038400\n",
        "*   https://uk.finance.yahoo.com/quote/AUDUSD%3DX/history/?period1=1690416000&period2=1722038400\n",
        "\n",
        "2. Select the Files icon from the left bar\n",
        "3. Find the 'content' folder and select the 3 dots\n",
        "4. Upload the downloaded files into 'content' folder"
      ],
      "metadata": {
        "id": "Nerp9r1_DbKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Paths to datasets\n",
        "dataset_paths = {\n",
        "    'AAPL': '/content/AAPL.csv',\n",
        "    'IXIC': '/content/IXIC.csv',\n",
        "    'NVDA': '/content/NVDA.csv',\n",
        "    'SPX': '/content/SPX.csv',\n",
        "    'GOOG': '/content/GOOG.csv',\n",
        "    'GBPUSD': '/content/GBPUSD=X.csv',\n",
        "    'EURUSD': '/content/EURUSD=X.csv',\n",
        "    'AUDUSD': '/content/AUDUSD=X.csv'\n",
        "}\n",
        "\n",
        "# Define required columns\n",
        "required_columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
        "\n",
        "# Loading datasets into a dictionary with date parsing\n",
        "datasets = {}\n",
        "for name, path in dataset_paths.items():\n",
        "    try:\n",
        "        # Load the dataset and parse 'Date' column\n",
        "        data = pd.read_csv(path, parse_dates=['Date'])\n",
        "        datasets[name] = data\n",
        "\n",
        "        # Check if required columns is in the dataset\n",
        "        missing_cols = [col for col in required_columns if col not in data.columns]\n",
        "        if missing_cols:\n",
        "            raise ValueError(f\"Dataset {name} is missing columns: {', '.join(missing_cols)}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File for {name} not found at {path}.\")\n",
        "    except pd.errors.ParserError:\n",
        "        print(f\"Error: Failed to parse the file for {name}.\")\n",
        "    except ValueError as e:\n",
        "        print(e)\n"
      ],
      "metadata": {
        "id": "-kXZ2yVaDOkc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Define Agent Behaviour"
      ],
      "metadata": {
        "id": "vidM0wNuzziJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from gym import Env, spaces"
      ],
      "metadata": {
        "id": "7lhhGDRZFz1P"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TradingEnv(Env):\n",
        "    def __init__(self, data):\n",
        "        super(TradingEnv, self).__init__()\n",
        "        self.data = data.copy()\n",
        "        self.current_step = 0\n",
        "        self.holdings = 0\n",
        "        self.balance = 1000\n",
        "\n",
        "        # Define action space: 0 = hold, 1 = buy, 2 = sell\n",
        "        self.action_space = spaces.Discrete(3)\n",
        "        # Observation space based on data columns (assuming normalized values between 0 and 1)\n",
        "        self.observation_space = spaces.Box(low=0, high=1, shape=(len(data.columns),), dtype=np.float32)\n",
        "\n",
        "    def reset(self):\n",
        "        # Reset the environment to the initial state\n",
        "        self.current_step = 0\n",
        "        self.holdings = 0\n",
        "        self.balance = 1000\n",
        "        return self.data.iloc[self.current_step].values  # Return the initial observation\n",
        "\n",
        "    def step(self, action):\n",
        "        # Perform one step in the environment based on the agent's action\n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= len(self.data) - 1\n",
        "\n",
        "        current_price = self.data.iloc[self.current_step]['Close']\n",
        "        initial_balance = self.balance\n",
        "\n",
        "        # Simulate price change based on action\n",
        "        price_change = 0\n",
        "        if action == 1:  # Buy\n",
        "            self.holdings += 1\n",
        "            price_change = current_price * 0.005  # Simulate a 0.5% price increase\n",
        "        elif action == 2:  # Sell\n",
        "            if self.holdings > 0:\n",
        "                self.holdings -= 1\n",
        "                price_change = -current_price * 0.005  # Simulate a 0.5% price decrease\n",
        "\n",
        "        # Update the price and balance\n",
        "        self.data.at[self.current_step, 'Close'] += price_change\n",
        "        self.balance += price_change * self.holdings\n",
        "\n",
        "        # Calculate net worth and reward\n",
        "        net_worth = self.balance + self.holdings * self.data.iloc[self.current_step]['Close']\n",
        "        reward = net_worth - initial_balance\n",
        "\n",
        "        # Observation for the next step\n",
        "        obs = self.data.iloc[self.current_step].values\n",
        "\n",
        "        return obs, reward, done, {}\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        # Render the environment (currently a placeholder)\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "JoFgUvbZFzx-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3978a138-983f-4591-dbd0-4fb103b52ce1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Traders\n",
        "class FundamentalTrader:\n",
        "    def __init__(self, fundamental_value, sensitivity=0.05):\n",
        "        self.fundamental_value = fundamental_value\n",
        "        self.sensitivity = sensitivity\n",
        "\n",
        "    def decide(self, price):\n",
        "        # Buy if price is significantly below fundamental value, sell if significantly above\n",
        "        if price < self.fundamental_value * (1 - self.sensitivity):\n",
        "            return 1  # Buy\n",
        "        elif price > self.fundamental_value * (1 + self.sensitivity):\n",
        "            return 2  # Sell\n",
        "        return 0  # Hold\n"
      ],
      "metadata": {
        "id": "x2gjkbG_FzsT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MomentumTrader:\n",
        "    def __init__(self, trend_length=3):\n",
        "        self.trend_length = trend_length\n",
        "        self.recent_prices = []\n",
        "\n",
        "    def decide(self, price):\n",
        "        # Buy if price is trending upward, sell if trending downward\n",
        "        self.recent_prices.append(price)\n",
        "        if len(self.recent_prices) > self.trend_length:\n",
        "            self.recent_prices.pop(0)\n",
        "\n",
        "        if len(self.recent_prices) < self.trend_length:\n",
        "            return 0  # Hold\n",
        "        if all(x < y for x, y in zip(self.recent_prices, self.recent_prices[1:])):\n",
        "            return 1  # Buy\n",
        "        elif all(x > y for x, y in zip(self.recent_prices, self.recent_prices[1:])):\n",
        "            return 2  # Sell\n",
        "        return 0  # Hold"
      ],
      "metadata": {
        "id": "QxQFZMRWFznQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomTrader:\n",
        "    def decide(self, price):\n",
        "        # Randomly decide between holding, buying, or selling\n",
        "        return np.random.choice([0, 1, 2])\n"
      ],
      "metadata": {
        "id": "fOFOCuPcFzjx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Calibration of Parameters\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ng5dZCzSl740"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Distance Function\n",
        "def distance_function(real_data, synthetic_data):\n",
        "    real_prices = real_data['Close'].values\n",
        "    synthetic_prices = synthetic_data['Close'].values\n",
        "    return mean_squared_error(real_prices, synthetic_prices)\n",
        "\n",
        "\n",
        "def generate_synthetic_data(traders, data):\n",
        "    env = TradingEnv(data)\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "\n",
        "    # Initialise trading env with real data, creates a simulation loop until trading is completed\n",
        "    while not done:\n",
        "        actions = [trader.decide(state[4]) for trader in traders]\n",
        "        action = max(set(actions), key=actions.count)\n",
        "        state, reward, done, _ = env.step(action)\n",
        "\n",
        "    # Converts the list of synthetic prices into a DataFrame.\n",
        "    synthetic_data = pd.DataFrame({\n",
        "        'Date': data['Date'],\n",
        "        'Close': [env.data.iloc[i]['Close'] for i in range(len(data))]\n",
        "    })\n",
        "    return synthetic_data\n"
      ],
      "metadata": {
        "id": "wtS8kTYGFzbu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading datasets\n",
        "\n",
        "for name, real_data in datasets.items():\n",
        "    real_data['Close'] = real_data['Adj Close']\n",
        "    fundamental_trader = FundamentalTrader(fundamental_value=150)\n",
        "    momentum_trader = MomentumTrader(trend_length=3)\n",
        "    random_trader = RandomTrader()\n",
        "\n",
        "    synthetic_data = generate_synthetic_data([fundamental_trader, momentum_trader, random_trader], real_data)\n",
        "\n",
        "    # Check if synthetic data matches real data\n",
        "    if real_data['Close'].equals(synthetic_data['Close']):\n",
        "        print(f\"Synthetic data for {name} is identical to real data.\")\n",
        "\n",
        "    distance = distance_function(real_data, synthetic_data)\n",
        "    print(f\"Distance (MSE) between real and synthetic data for {name}: {distance}\")"
      ],
      "metadata": {
        "id": "7i04wC8oFzQX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0e515d2-6ba1-4381-a2a3-8031c786f792"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance (MSE) between real and synthetic data for AAPL: 0.19035480687661124\n",
            "Distance (MSE) between real and synthetic data for IXIC: 1189.1838414878057\n",
            "Distance (MSE) between real and synthetic data for NVDA: 0.09751629765779138\n",
            "Distance (MSE) between real and synthetic data for SPX: 120.44924315827969\n",
            "Distance (MSE) between real and synthetic data for GOOG: 0.28954118126302286\n",
            "Distance (MSE) between real and synthetic data for GBPUSD: 2.3937435925880793e-05\n",
            "Distance (MSE) between real and synthetic data for EURUSD: 1.7344663995307758e-05\n",
            "Distance (MSE) between real and synthetic data for AUDUSD: 6.1485053261951485e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Parameter Tuning\n"
      ],
      "metadata": {
        "id": "nclu4VOCmGov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipython-autotime\n",
        "\n",
        "%load_ext autotime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UT2JdoS0wZya",
        "outputId": "12896d56-cf22-404e-fc8f-252e77d384c9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipython-autotime in /usr/local/lib/python3.10/dist-packages (0.3.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipython-autotime) (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (71.0.4)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.13)\n",
            "time: 602 µs (started: 2024-09-11 16:37:40 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Grid Search:"
      ],
      "metadata": {
        "id": "2EGL6aIymKIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "\n",
        "def grid_search_tuning(trader_classes, param_grid, data):\n",
        "    best_params = None\n",
        "    best_mse = float('inf') # Initialise to infinity for comparison\n",
        "\n",
        "    # Iterate over every combination of parameters using the Cartesian product\n",
        "    for params in product(*param_grid.values()):\n",
        "        # Set parameters\n",
        "        fundamental_value, sensitivity, trend_length = params\n",
        "\n",
        "        trader_classes[0].fundamental_value = fundamental_value\n",
        "        trader_classes[0].sensitivity = sensitivity\n",
        "        trader_classes[1].trend_length = trend_length\n",
        "\n",
        "        # Generate synthetic data and calculate MSE\n",
        "        synthetic_data = generate_synthetic_data(trader_classes, data)\n",
        "        mse = distance_function(data, synthetic_data)\n",
        "\n",
        "        # Update the best parameters if a lower MSE is found\n",
        "        if mse < best_mse:\n",
        "            best_mse = mse\n",
        "            best_params = params\n",
        "\n",
        "    return best_params, best_mse"
      ],
      "metadata": {
        "id": "S3xiWbDF-O0-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e6d5c54-b426-4195-b1ce-554513d73c06"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.17 ms (started: 2024-09-11 16:37:40 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameter grid for grid search\n",
        "param_grid = {\n",
        "    'fundamental_value': [140, 150, 160],\n",
        "    'sensitivity': [0.02, 0.05, 0.1],\n",
        "    'trend_length': [3, 5, 7]\n",
        "}\n",
        "\n",
        "# Perform grid search on each dataset\n",
        "for name, real_data in datasets.items():\n",
        "    print(f\"\\nGrid search for {name} dataset\")\n",
        "    fundamental_trader = FundamentalTrader(fundamental_value=150)\n",
        "    momentum_trader = MomentumTrader(trend_length=3)\n",
        "    random_trader = RandomTrader()\n",
        "\n",
        "    trader_classes = [fundamental_trader, momentum_trader, random_trader]\n",
        "    best_params, best_mse = grid_search_tuning(trader_classes, param_grid, real_data)\n",
        "\n",
        "    print(f\"Best parameters (Grid Search): {best_params}\")\n",
        "    print(f\"Best MSE (Grid Search): {best_mse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyMsRLVj-PJc",
        "outputId": "056f1d47-8e31-4ef2-e0cc-ec252aad2593"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Grid search for AAPL dataset\n",
            "Best parameters (Grid Search): (140, 0.1, 3)\n",
            "Best MSE (Grid Search): 0.0\n",
            "\n",
            "Grid search for IXIC dataset\n",
            "Best parameters (Grid Search): (140, 0.1, 5)\n",
            "Best MSE (Grid Search): 81.13982310049677\n",
            "\n",
            "Grid search for NVDA dataset\n",
            "Best parameters (Grid Search): (140, 0.1, 5)\n",
            "Best MSE (Grid Search): 0.04213849098155099\n",
            "\n",
            "Grid search for SPX dataset\n",
            "Best parameters (Grid Search): (160, 0.05, 3)\n",
            "Best MSE (Grid Search): 0.0\n",
            "\n",
            "Grid search for GOOG dataset\n",
            "Best parameters (Grid Search): (140, 0.1, 3)\n",
            "Best MSE (Grid Search): 0.014616066413562435\n",
            "\n",
            "Grid search for GBPUSD dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualise Volatility of IXIC and SPX"
      ],
      "metadata": {
        "id": "QZF3SCkPhKwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load IXIC and SPX data from Yahoo Finance\n",
        "ixic = yf.download('^IXIC', start='2023-07-27', end='2024-07-26')\n",
        "spx = yf.download('^GSPC', start='2023-07-27', end='2024-07-26')\n",
        "\n",
        "# Calculate daily returns for both IXIC and SPX\n",
        "ixic['Returns'] = ixic['Close'].pct_change()\n",
        "spx['Returns'] = spx['Close'].pct_change()\n",
        "\n",
        "\n",
        "# Calculate rolling volatility (21-day window) for both IXIC and SPX\n",
        "ixic['Rolling_Volatility'] = ixic['Returns'].rolling(window=21).std()\n",
        "spx['Rolling_Volatility'] = spx['Returns'].rolling(window=21).std()\n",
        "\n",
        "\n",
        "# Plot the rolling volatility of both indices\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(ixic.index, ixic['Rolling_Volatility'], label='IXIC Rolling Volatility (21-day)', color='blue')\n",
        "plt.plot(spx.index, spx['Rolling_Volatility'], label='SPX Rolling Volatility (21-day)', color='green')\n",
        "plt.title('Rolling Volatility Comparison (IXIC and SPX)')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Volatility')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Rxf0y9VQ2cd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Random Search:"
      ],
      "metadata": {
        "id": "-9x2DKJ6mWUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Search Tuning\n",
        "import random\n",
        "\n",
        "def random_search_tuning(trader_classes, param_distributions, n_iter, data):\n",
        "    best_params = None\n",
        "    best_mse = float('inf')\n",
        "\n",
        "    for _ in range(n_iter):\n",
        "        # Randomly sample parameters\n",
        "        fundamental_value = random.choice(param_distributions['fundamental_value'])\n",
        "        sensitivity = random.choice(param_distributions['sensitivity'])\n",
        "        trend_length = random.choice(param_distributions['trend_length'])\n",
        "\n",
        "        # Set parameters\n",
        "        trader_classes[0].fundamental_value = fundamental_value\n",
        "        trader_classes[0].sensitivity = sensitivity\n",
        "        trader_classes[1].trend_length = trend_length\n",
        "\n",
        "        # Generate synthetic data and calculate MSE\n",
        "        synthetic_data = generate_synthetic_data(trader_classes, data)\n",
        "        mse = distance_function(data, synthetic_data)\n",
        "\n",
        "        if mse < best_mse:\n",
        "            best_mse = mse\n",
        "            best_params = (fundamental_value, sensitivity, trend_length)\n",
        "\n",
        "    return best_params, best_mse"
      ],
      "metadata": {
        "id": "Igdz7NJr-aq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameter grid for random search\n",
        "param_distributions = {\n",
        "    'fundamental_value': [140, 150, 160],\n",
        "    'sensitivity': [0.02, 0.05, 0.1],\n",
        "    'trend_length': [3, 5, 7]\n",
        "}\n",
        "\n",
        "# n_iter determines how many random samples will be tested.\n",
        "n_iter = 10\n",
        "\n",
        "for name, real_data in datasets.items():\n",
        "    print(f\"\\nRandom search for {name} dataset\")\n",
        "    fundamental_trader = FundamentalTrader(fundamental_value=150)\n",
        "    momentum_trader = MomentumTrader(trend_length=3)\n",
        "    random_trader = RandomTrader()\n",
        "\n",
        "    trader_classes = [fundamental_trader, momentum_trader, random_trader]\n",
        "    best_params, best_mse = random_search_tuning(trader_classes, param_distributions, n_iter, real_data)\n",
        "    print(f\"Best parameters (Random Search): {best_params}\")\n",
        "    print(f\"Best MSE (Random Search): {best_mse}\")"
      ],
      "metadata": {
        "id": "_PtRLpSa-bbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Bayesian Optimisation:"
      ],
      "metadata": {
        "id": "O6JqO60RmaGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize"
      ],
      "metadata": {
        "id": "tG3-e1vQ-goe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import gp_minimize\n",
        "from skopt.space import Real, Integer\n",
        "from skopt.utils import use_named_args\n",
        "from skopt.acquisition import gaussian_ei\n",
        "\n",
        "# Bayesian Optimisation Tuning\n",
        "def bayesian_optimization_tuning(trader_classes, data):\n",
        "    # Define the parameter space\n",
        "    space = [\n",
        "        Integer(140, 160, name='fundamental_value'),\n",
        "        Real(0.01, 0.1, name='sensitivity'),\n",
        "        Integer(3, 7, name='trend_length')\n",
        "    ]\n",
        "\n",
        "    @use_named_args(space)\n",
        "    def objective(**params):\n",
        "        trader_classes[0].fundamental_value = params['fundamental_value']\n",
        "        trader_classes[0].sensitivity = params['sensitivity']\n",
        "        trader_classes[1].trend_length = params['trend_length']\n",
        "\n",
        "        synthetic_data = generate_synthetic_data(trader_classes, data)\n",
        "        return distance_function(data, synthetic_data)\n",
        "\n",
        "    res = gp_minimize(objective, space, n_calls=20, random_state=42, acq_func=\"EI\")\n",
        "    return res.x, res.fun\n"
      ],
      "metadata": {
        "id": "yK9Jbl7v-iSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Bayes Optimisation search for each dataset\n",
        "for name, real_data in datasets.items():\n",
        "    print(f\"\\nBayesian Optimisation for {name} dataset\")\n",
        "    fundamental_trader = FundamentalTrader(fundamental_value=150)\n",
        "    momentum_trader = MomentumTrader(trend_length=3)\n",
        "    random_trader = RandomTrader()\n",
        "\n",
        "    # Perform Bayesian Optimisation\n",
        "    best_params, best_mse = bayesian_optimization_tuning(trader_classes, real_data)\n",
        "    print(f\"Best parameters (Bayesian Optimisation): {best_params}\")\n",
        "    print(f\"Best MSE (Bayesian Optimisation): {best_mse}\")\n"
      ],
      "metadata": {
        "id": "1D4I4WM3-jjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Greedy Search:"
      ],
      "metadata": {
        "id": "XCmCngnKmkPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Greedy Search Tuning\n",
        "def greedy_search(trader_classes, real_data):\n",
        "    best_distance = float('inf')\n",
        "    best_params = None\n",
        "\n",
        "    # Parameter ranges\n",
        "    fundamental_values = [140, 150, 160]\n",
        "    sensitivities = [0.02, 0.05, 0.1]\n",
        "    trend_lengths = [3, 5, 7]\n",
        "\n",
        "    # Iterate through all combinations\n",
        "    for fundamental_value in fundamental_values:\n",
        "        for trend_length in trend_lengths:\n",
        "            for sensitivity in sensitivities:\n",
        "                # Set trader parameters\n",
        "                trader_classes[0].fundamental_value = fundamental_value\n",
        "                trader_classes[0].sensitivity = sensitivity\n",
        "                trader_classes[1].trend_length = trend_length\n",
        "\n",
        "                # Generate synthetic data and calculate distance\n",
        "                synthetic_data = generate_synthetic_data(trader_classes, real_data)\n",
        "                distance = distance_function(real_data, synthetic_data)\n",
        "\n",
        "                if distance < best_distance:\n",
        "                    best_distance = distance\n",
        "                    best_params = (fundamental_value, sensitivity, trend_length)\n",
        "\n",
        "    print(f\"Best parameters (Greedy Search): Fundamental value = {best_params[0]}, Sensitivity = {best_params[1]}, Trend length = {best_params[2]}\")\n",
        "    print(f\"Best MSE (Greedy Search): {best_distance}\")\n"
      ],
      "metadata": {
        "id": "S7ask52X-msA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameter grid for Greedy search\n",
        "param_distributions = {\n",
        "    'fundamental_value': [140, 150, 160],\n",
        "    'sensitivity': [0.02, 0.05, 0.1],\n",
        "    'trend_length': [3, 5, 7]\n",
        "}\n",
        "\n",
        "for name, real_data in datasets.items():\n",
        "    print(f\"\\nGreedy search for {name} dataset\")\n",
        "    fundamental_trader = FundamentalTrader(fundamental_value=150)\n",
        "    momentum_trader = MomentumTrader(trend_length=3)\n",
        "    random_trader = RandomTrader()\n",
        "\n",
        "    # Perform Greedy Search\n",
        "    greedy_search(trader_classes, real_data)\n"
      ],
      "metadata": {
        "id": "cT6Qkohi-m6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Reinforcement Learning:"
      ],
      "metadata": {
        "id": "AOPGuVw0mn2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QLearningAgent:\n",
        "    def __init__(self, state_space, action_space, alpha=0.1, gamma=0.9, epsilon=0.1):\n",
        "        self.q_table = np.zeros((state_space, action_space))\n",
        "        self.alpha = alpha  # Learning rate\n",
        "        self.gamma = gamma  # Discount factor\n",
        "        self.epsilon = epsilon  # Exploration rate\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        state = int(state)\n",
        "        # Generates random number and compares it to epsilon. If it's less than epsilon, it explores by choosing a random action\n",
        "        if np.random.uniform(0, 1) < self.epsilon:\n",
        "            return np.random.choice(range(self.q_table.shape[1]))\n",
        "        else:\n",
        "            # Returns action with the highest Q-value for the current state\n",
        "            return np.argmax(self.q_table[state])\n",
        "\n",
        "    def update(self, state, action, reward, next_state):\n",
        "        state = int(state)\n",
        "        next_state = int(next_state)\n",
        "        predict = self.q_table[state, action]\n",
        "        # Calculates target Q-value based on reward and maximum Q-value of next state\n",
        "        target = reward + self.gamma * np.max(self.q_table[next_state])\n",
        "        # Updates Q-value for state-action pair using the learning rate\n",
        "        self.q_table[state, action] += self.alpha * (target - predict)"
      ],
      "metadata": {
        "id": "xi2WVGNL-sEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simplified Trading Environment\n",
        "class TradingEnvRL:\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        self.current_step = 0\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_step = 0\n",
        "        return self.current_step\n",
        "\n",
        "    def step(self, action):\n",
        "        self.current_step += 1\n",
        "        if self.current_step >= len(self.data) - 1:\n",
        "            done = True\n",
        "            next_state = 0\n",
        "        else:\n",
        "            done = False\n",
        "            next_state = self.current_step\n",
        "\n",
        "        # Calculates reward as the change in closing price between current and previous steps\n",
        "        reward = self.data.iloc[self.current_step]['Close'] - self.data.iloc[self.current_step - 1]['Close']\n",
        "        # If agent chose to buy (action == 1), the reward is positive; otherwise, it's negative\n",
        "        reward = reward if action == 1 else -reward\n",
        "\n",
        "        return next_state, reward, done, {}"
      ],
      "metadata": {
        "id": "xlM1RWBR-tx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_rl_agent(agent, episodes, trader_classes, real_data):\n",
        "    env = TradingEnvRL(real_data)\n",
        "\n",
        "    global best_mse  # Make sure we are updating the global best_mse\n",
        "    global best_params  # Tracking best parameters\n",
        "\n",
        "    for episode in range(episodes):\n",
        "        state = env.reset()\n",
        "        done = False\n",
        "\n",
        "        while not done:\n",
        "            # Agent chooses action based on current state\n",
        "            action = agent.choose_action(state)\n",
        "            # Takes a step in the environment and gets next state, reward, and done flag\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "            agent.update(state, action, reward, next_state)\n",
        "            state = next_state\n",
        "\n",
        "        # Adjust parameters based on learned policy\n",
        "        # Determines the best action by summing Q-values across all states and finding the maximum\n",
        "        best_action = np.argmax(agent.q_table.sum(axis=0))\n",
        "        fundamental_trader.fundamental_value = 140 + best_action * 10  # Example adjustment\n",
        "        momentum_trader.trend_length = 3 + best_action * 2  # Example adjustment\n",
        "\n",
        "        # Generate synthetic data and calculate the distance (MSE)\n",
        "        synthetic_data = generate_synthetic_data([fundamental_trader, momentum_trader, random_trader], real_data)\n",
        "        distance = distance_function(real_data, synthetic_data)\n",
        "\n",
        "        # Check if this is the best MSE so far\n",
        "        if distance < best_mse:\n",
        "            best_mse = distance\n",
        "            best_params = {\"best_action\": best_action}  # Example for best parameters\n",
        "\n",
        "        print(f\"Episode {episode+1}/{episodes}: Distance = {distance}\")\n"
      ],
      "metadata": {
        "id": "iPZs6QHu-vjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, real_data in datasets.items():\n",
        "    print(f\"\\nReinforcement Learning for {name} dataset\")\n",
        "    agent = QLearningAgent(state_space=len(real_data), action_space=3)  # Adjust dimensions as needed\n",
        "    fundamental_trader = FundamentalTrader(fundamental_value=150)\n",
        "    momentum_trader = MomentumTrader(trend_length=3)\n",
        "    random_trader = RandomTrader()\n",
        "\n",
        "    # Episode means for each day, may not be consecutive\n",
        "    train_rl_agent(agent, episodes=10, trader_classes=[fundamental_trader, momentum_trader, random_trader], real_data=real_data)\n"
      ],
      "metadata": {
        "id": "OQjRiln--xa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import deque\n",
        "import random\n",
        "\n",
        "# Neural Network for Deep Q-Learning\n",
        "class DQNetwork(nn.Module):\n",
        "    def __init__(self, state_size, action_size):\n",
        "        super(DQNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_size, 24)\n",
        "        self.fc2 = nn.Linear(24, 24)\n",
        "        self.fc3 = nn.Linear(24, action_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Passes the input through the first layer and applies ReLU activation\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        # Returns the final Q-values\n",
        "        return self.fc3(x)\n",
        "\n",
        "# Deep Q-Learning Agent\n",
        "class DQNAgent:\n",
        "    def __init__(self, state_size, action_size):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.memory = deque(maxlen=2000) # Initialises the memory buffer with a maximum length of 2000\n",
        "        self.gamma = 0.95    # Discount rate\n",
        "        self.epsilon = 1.0   # Exploration rate\n",
        "        self.epsilon_min = 0.01\n",
        "        self.epsilon_decay = 0.995\n",
        "        self.learning_rate = 0.001\n",
        "        self.model = DQNetwork(state_size, action_size)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "    # Stores an experience in memory\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def act(self, state):\n",
        "        # With probability epsilon, choose a random action\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return random.randrange(self.action_size)\n",
        "        # Converts the state to a tensor\n",
        "        state = torch.tensor(state, dtype=torch.float32)\n",
        "        # Passes the state through the model to get Q-values\n",
        "        act_values = self.model(state)\n",
        "        # Returns the action with the highest Q-value\n",
        "        return torch.argmax(act_values).item()\n",
        "\n",
        "    def replay(self, batch_size):\n",
        "        # Samples a random minibatch from memory\n",
        "        minibatch = random.sample(self.memory, batch_size)\n",
        "        for state, action, reward, next_state, done in minibatch:\n",
        "            target = reward\n",
        "            # If the episode is not done, calculate the target with future rewards\n",
        "            if not done:\n",
        "                # Converts the next state to a tensor\n",
        "                next_state = torch.tensor(next_state, dtype=torch.float32)\n",
        "                # Updates the target with the maximum Q-value of the next state\n",
        "                target = reward + self.gamma * torch.max(self.model(next_state)).item()\n",
        "            state = torch.tensor(state, dtype=torch.float32)\n",
        "            # Predicts the Q-values for the current state\n",
        "            target_f = self.model(state)\n",
        "            # Updates the Q-value for the chosen action\n",
        "            target_f[action] = target\n",
        "            # Clears the gradients of the model parameters\n",
        "            self.optimizer.zero_grad()\n",
        "            # Calculates the loss between the target and predicted Q-values\n",
        "            loss = self.criterion(target_f, self.model(state))\n",
        "            # Backpropagates the loss\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "def train_dqn_agent(agent, episodes, batch_size, trader_classes, real_data):\n",
        "    global best_mse  # Best MSE across episodes\n",
        "    global best_params\n",
        "\n",
        "    for episode in range(episodes):\n",
        "        env = TradingEnvRL(real_data)\n",
        "        state = env.reset()\n",
        "        state = np.array([state])\n",
        "\n",
        "        for time in range(len(real_data)):\n",
        "            action = agent.act(state)\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "            next_state = np.array([next_state])\n",
        "            agent.remember(state, action, reward, next_state, done)\n",
        "            state = next_state\n",
        "            if done:\n",
        "                print(f\"Episode {episode+1}/{episodes} finished after {time+1} timesteps\")\n",
        "                break\n",
        "        # If there are enough experiences in memory, start replaying\n",
        "        if len(agent.memory) > batch_size:\n",
        "            agent.replay(batch_size)\n",
        "\n",
        "        # Adjust trader parameters based on the best action\n",
        "        best_action = np.argmax(agent.model(torch.tensor(state, dtype=torch.float32)).detach().numpy())\n",
        "        fundamental_trader.fundamental_value = 140 + best_action * 10\n",
        "        momentum_trader.trend_length = 3 + best_action * 2\n",
        "\n",
        "        # Generate synthetic data and calculate the MSE\n",
        "        synthetic_data = generate_synthetic_data([fundamental_trader, momentum_trader, random_trader], real_data)\n",
        "        distance = distance_function(real_data, synthetic_data)\n",
        "\n",
        "        if distance < best_mse:\n",
        "            best_mse = distance\n",
        "            best_params = {\"best_action\": best_action}\n",
        "\n",
        "        print(f\"Episode {episode+1}/{episodes}: Distance = {distance}\")\n"
      ],
      "metadata": {
        "id": "oJpA7nER-1al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store best MSE and best parameters for each dataset\n",
        "best_mse_per_dataset = {}\n",
        "\n",
        "for name, real_data in datasets.items():\n",
        "    print(f\"\\nReinforcement Learning for {name} dataset\")\n",
        "\n",
        "    agent = QLearningAgent(state_space=len(real_data), action_space=3)  # Adjust dimensions as needed\n",
        "    fundamental_trader = FundamentalTrader(fundamental_value=150)\n",
        "    momentum_trader = MomentumTrader(trend_length=3)\n",
        "    random_trader = RandomTrader()\n",
        "\n",
        "    # Reset best MSE and best parameters for this dataset\n",
        "    best_mse = float('inf')\n",
        "    best_params = None\n",
        "\n",
        "    train_rl_agent(agent, episodes=10, trader_classes=[fundamental_trader, momentum_trader, random_trader], real_data=real_data)\n",
        "\n",
        "    # Store best MSE and parameters for this dataset\n",
        "    best_mse_per_dataset[name] = {\"best_mse\": best_mse, \"best_params\": best_params}\n",
        "\n",
        "# After training, print the best MSE per dataset\n",
        "for name, mse_data in best_mse_per_dataset.items():\n",
        "    print(f\"\\nReinforcement Learning for {name} dataset\")\n",
        "    print(f\"Best MSE (Reinforcement Learning): {mse_data['best_mse']}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "qHGmdLy4rZ_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Evaluate Performance, Calibrate Distance Function, and Visualize"
      ],
      "metadata": {
        "id": "ObGe2LG9m4ri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import euclidean\n",
        "\n",
        "def evaluate_model(real_data, predicted_data, parameter_sets):\n",
        "    \"\"\"\n",
        "    Evaluates the performance of the model using the mean squared error and calibrates the distance function.\n",
        "\n",
        "    Args:\n",
        "    - real_data: Array of real-world data.\n",
        "    - predicted_data: Array of predicted data from the model.\n",
        "    - parameter_sets: List of parameter sets used in the model.\n",
        "\n",
        "    Returns:\n",
        "    - performance_scores: List of performance scores (e.g., MSE) for each parameter set.\n",
        "    - distance_scores: List of distance scores between parameter sets and real-world data.\n",
        "    \"\"\"\n",
        "    performance_scores = []\n",
        "    distance_scores = []\n",
        "\n",
        "    for i, predicted in enumerate(predicted_data):\n",
        "        mse = mean_squared_error(real_data, predicted)\n",
        "        performance_scores.append(mse)\n",
        "\n",
        "        # Calculates the Euclidean distance between the current parameter set and real_data\n",
        "        distance = euclidean(parameter_sets[i], real_data)\n",
        "        # Adds the distance to the distance_scores list\n",
        "        distance_scores.append(distance)\n",
        "\n",
        "    return performance_scores, distance_scores\n",
        "\n",
        "# Example data\n",
        "real_data = np.array([1.2, 2.5, 3.8])\n",
        "predicted_data = [np.array([1.1, 2.6, 3.7]), np.array([1.3, 2.4, 3.9])]\n",
        "parameter_sets = [np.array([0.9, 2.7, 3.6]), np.array([1.4, 2.3, 4.0])]\n",
        "\n",
        "performance_scores, distance_scores = evaluate_model(real_data, predicted_data, parameter_sets)\n",
        "\n",
        "print(\"Performance Scores (MSE):\", performance_scores)\n",
        "print(\"Distance Scores:\", distance_scores)\n",
        "\n",
        "# Calibrate distance function (example step)\n",
        "min_distance = min(distance_scores)\n",
        "# Normalizes the distance scores by dividing by the minimum distance\n",
        "calibrated_distances = [d / min_distance for d in distance_scores]\n",
        "\n",
        "print(\"Calibrated Distances:\", calibrated_distances)"
      ],
      "metadata": {
        "id": "FYH0SudK-5bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def evaluate_model(real_data, predicted_data, parameter_sets):\n",
        "    performance_scores = []\n",
        "    distance_scores = []\n",
        "\n",
        "    for i, predicted in enumerate(predicted_data):\n",
        "        mse = mean_squared_error(real_data, predicted)\n",
        "        performance_scores.append(mse)\n",
        "\n",
        "        distance = euclidean(parameter_sets[i], real_data)\n",
        "        distance_scores.append(distance)\n",
        "\n",
        "    return performance_scores, distance_scores"
      ],
      "metadata": {
        "id": "t0wx17G2-5sY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_performance(performance_scores, distance_scores):\n",
        "    # Create a scatter plot to visualise relationship between performance and distance\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.scatterplot(x=distance_scores, y=performance_scores, s=100)\n",
        "    plt.title(\"Performance vs. Distance\")\n",
        "    plt.xlabel(\"Distance Score\")\n",
        "    plt.ylabel(\"Performance Score (MSE)\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Plotting performance scores\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(performance_scores, marker='o', linestyle='-', color='b')\n",
        "    plt.title(\"Performance Scores (MSE) Across Parameter Sets\")\n",
        "    plt.xlabel(\"Parameter Set Index\")\n",
        "    plt.ylabel(\"Performance Score (MSE)\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Plotting distance scores\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(distance_scores, marker='o', linestyle='-', color='r')\n",
        "    plt.title(\"Distance Scores Across Parameter Sets\")\n",
        "    plt.xlabel(\"Parameter Set Index\")\n",
        "    plt.ylabel(\"Distance Score\")\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "XT4P-s-Q-8x7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calibrate distance function (example step)\n",
        "min_distance = min(distance_scores)\n",
        "\n",
        "# Check to prevent division by zero\n",
        "if min_distance == 0:\n",
        "    # Skip normalisation because it would disrupt/manipulate model calibration\n",
        "    calibrated_distances = distance_scores\n",
        "    print(\"Min distance is zero, skipping normalization.\")\n",
        "else:\n",
        "    # If minimum distance is not zero, normalises distance scores by dividing each by the minimum distance\n",
        "    # This step calibrates the distances, making the smallest distance equal to 1 and scaling the others accordingly\n",
        "    calibrated_distances = [d / min_distance for d in distance_scores]\n",
        "\n",
        "print(\"Performance Scores (MSE):\", performance_scores)\n",
        "print(\"Distance Scores:\", distance_scores)\n",
        "print(\"Calibrated Distances:\", calibrated_distances)"
      ],
      "metadata": {
        "id": "3R2BTiKu-8_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data for plotting\n",
        "methods = ['Method 1', 'Method 2', 'Method 3']\n",
        "mse_scores = performance_scores  # Ensure length matches 'methods'\n",
        "distance_scores = distance_scores\n",
        "calibrated_distances = calibrated_distances\n",
        "\n",
        "# Check if all lists have the same length\n",
        "if len(methods) == len(mse_scores) == len(distance_scores) == len(calibrated_distances):\n",
        "    # Plotting the MSE Scores\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.bar(methods, mse_scores, color='skyblue')\n",
        "    plt.title('Performance Scores (MSE)')\n",
        "    plt.ylabel('MSE')\n",
        "\n",
        "    # Plotting the Distance Scores\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.bar(methods, distance_scores, color='lightgreen')\n",
        "    plt.title('Distance Scores')\n",
        "    plt.ylabel('Distance')\n",
        "\n",
        "    # Plotting the Calibrated Distances\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.bar(methods, calibrated_distances, color='salmon')\n",
        "    plt.title('Calibrated Distances')\n",
        "    plt.ylabel('Calibrated Distance')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"Error: Length mismatch between 'methods' and score arrays.\")"
      ],
      "metadata": {
        "id": "BtHbd1iz_A-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate and plot results\n",
        "def evaluate_and_plot(trader_classes, real_data, method_name, best_params):\n",
        "    # Set the best parameters for the traders\n",
        "    fundamental_value, sensitivity, trend_length = best_params\n",
        "    trader_classes[0].fundamental_value = fundamental_value\n",
        "    trader_classes[0].sensitivity = sensitivity\n",
        "    trader_classes[1].trend_length = trend_length\n",
        "\n",
        "    # Generate synthetic data using the best parameters\n",
        "    synthetic_data = generate_synthetic_data(trader_classes, real_data)\n",
        "\n",
        "    # Calculate distance (MSE) between real and synthetic data\n",
        "    distance = distance_function(real_data, synthetic_data)\n",
        "\n",
        "    # Plot the real and synthetic closing prices\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(real_data['Date'], real_data['Close'], label='Real Data')\n",
        "    plt.plot(synthetic_data['Date'], synthetic_data['Close'], label='Synthetic Data')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Closing Price')\n",
        "    plt.title(f'Real vs Synthetic Data - {method_name}\\nMSE: {distance:.10f}')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return distance\n",
        "\n",
        "# Modified function for greedy search to return best parameters\n",
        "def greedy_search_with_plot(trader_classes, real_data):\n",
        "    best_distance = float('inf')\n",
        "    best_params = None\n",
        "\n",
        "    fundamental_values = [140, 150, 160]\n",
        "    trend_lengths = [3, 5, 7]\n",
        "\n",
        "    for fundamental_value in fundamental_values:\n",
        "        for trend_length in trend_lengths:\n",
        "            trader_classes[0].fundamental_value = fundamental_value\n",
        "            trader_classes[1].trend_length = trend_length\n",
        "\n",
        "            synthetic_data = generate_synthetic_data(trader_classes, real_data)\n",
        "            distance = distance_function(real_data, synthetic_data)\n",
        "\n",
        "            if distance < best_distance:\n",
        "                best_distance = distance\n",
        "                best_params = (fundamental_value, trend_length)\n",
        "\n",
        "    print(f\"Greedy Search Best Params: Fundamental value = {best_params[0]}, Trend length = {best_params[1]}\")\n",
        "    print(f\"Greedy Search Best Distance: {best_distance:.4f}\")\n",
        "\n",
        "    # Plot the results\n",
        "    sensitivity = trader_classes[0].sensitivity  # Retain sensitivity value\n",
        "    return evaluate_and_plot(trader_classes, real_data, \"Greedy Search\", (best_params[0], sensitivity, best_params[1]))\n",
        "\n",
        "# Function to train RL agent and plot results\n",
        "def train_and_plot_rl(trader_classes, agent, real_data, method_name, episodes=10):\n",
        "    for episode in range(episodes):\n",
        "        state = 0\n",
        "        done = False\n",
        "        env = TradingEnvRL(real_data)\n",
        "        state = env.reset()\n",
        "\n",
        "        while not done:\n",
        "            action = agent.choose_action(state)\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "            agent.update(state, action, reward, next_state)\n",
        "            state = next_state\n",
        "\n",
        "        best_action = np.argmax(agent.q_table.sum(axis=0))\n",
        "        trader_classes[0].fundamental_value = 140 + best_action * 10\n",
        "        trader_classes[1].trend_length = 3 + best_action * 2\n",
        "\n",
        "    # After training, evaluate and plot results\n",
        "    sensitivity = trader_classes[0].sensitivity  # Retain sensitivity value\n",
        "    evaluate_and_plot(trader_classes, real_data, method_name, (trader_classes[0].fundamental_value, sensitivity, trader_classes[1].trend_length))\n",
        "\n",
        "for name, real_data in datasets.items():\n",
        "    print(f\"\\nEvaluating performance for dataset: {name}\")\n",
        "\n",
        "    # Initialise traders with default values\n",
        "    fundamental_trader = FundamentalTrader(fundamental_value=150)\n",
        "    momentum_trader = MomentumTrader(trend_length=3)\n",
        "    random_trader = RandomTrader()\n",
        "    trader_classes = [fundamental_trader, momentum_trader, random_trader]\n",
        "\n",
        "    # Grid search best params\n",
        "    grid_best_params, _ = grid_search_tuning(trader_classes, param_grid, real_data)\n",
        "    grid_mse = evaluate_and_plot(trader_classes, real_data, \"Grid Search\", grid_best_params)\n",
        "\n",
        "    # Random search best params\n",
        "    random_best_params, _ = random_search_tuning(trader_classes, param_distributions, n_iter, real_data)\n",
        "    random_mse = evaluate_and_plot(trader_classes, real_data, \"Random Search\", random_best_params)\n",
        "\n",
        "    # Bayesian optimization best params\n",
        "    bayesian_best_params, _ = bayesian_optimization_tuning(trader_classes, real_data)\n",
        "    bayesian_mse = evaluate_and_plot(trader_classes, real_data, \"Bayesian Optimisation\", bayesian_best_params)\n",
        "\n",
        "    # Greedy search best params and plot\n",
        "    greedy_mse = greedy_search_with_plot(trader_classes, real_data)\n",
        "\n",
        "    # Reinforcement Learning\n",
        "    print(f\"\\nReinforcement Learning for {name} dataset\")\n",
        "    agent = QLearningAgent(state_space=len(real_data), action_space=3)\n",
        "    train_and_plot_rl(trader_classes, agent, real_data, \"Reinforcement Learning\")\n",
        "\n",
        "    print(f\"Summary for {name}:\")\n",
        "    print(f\"Grid Search MSE: {grid_mse:.10f}\")\n",
        "    print(f\"Random Search MSE: {random_mse:.10f}\")\n",
        "    print(f\"Bayesian Optimisation MSE: {bayesian_mse:.10f}\")\n",
        "    print(f\"Greedy Search MSE: {greedy_mse:.10f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "7pl1p52AvC6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "def greedy_search_with_plot(trader_classes, real_data, n_splits=5):\n",
        "    best_distance = float('inf')\n",
        "    best_params = None\n",
        "\n",
        "    fundamental_values = [140, 150, 160]\n",
        "    trend_lengths = [3, 5, 7]\n",
        "\n",
        "    for fundamental_value in fundamental_values:\n",
        "        for trend_length in trend_lengths:\n",
        "            trader_classes[0].fundamental_value = fundamental_value\n",
        "            trader_classes[1].trend_length = trend_length\n",
        "\n",
        "            synthetic_data = generate_synthetic_data(trader_classes, real_data)\n",
        "            distance = distance_function(real_data, synthetic_data)\n",
        "\n",
        "            if distance < best_distance:\n",
        "                best_distance = distance\n",
        "                best_params = (fundamental_value, trend_length)\n",
        "\n",
        "    print(f\"Greedy Search Best Params: Fundamental value = {best_params[0]}, Trend length = {best_params[1]}\")\n",
        "    print(f\"Greedy Search Best Distance: {best_distance:.4f}\")\n",
        "\n",
        "    # Perform cross-validation using the best parameters\n",
        "    fold_mse = cross_validate(trader_classes, real_data, \"Greedy Search\", (best_params[0], trader_classes[0].sensitivity, best_params[1]), n_splits)\n",
        "\n",
        "    return fold_mse  # Return the list of MSE values for each fold\n",
        "\n",
        "def train_and_plot_rl(trader_classes, agent, real_data, method_name, episodes=10, n_splits=5):\n",
        "    # Placeholder to store MSE values across folds\n",
        "    fold_mse = []\n",
        "\n",
        "    # K-Fold Cross-Validation setup\n",
        "    kf = KFold(n_splits=n_splits)\n",
        "\n",
        "    for train_index, test_index in kf.split(real_data):\n",
        "        # Split data into train and test sets\n",
        "        train_data, test_data = real_data.iloc[train_index].reset_index(drop=True), real_data.iloc[test_index].reset_index(drop=True)\n",
        "\n",
        "        # Train the RL agent on the train set\n",
        "        for episode in range(episodes):\n",
        "            state = 0\n",
        "            done = False\n",
        "            env = TradingEnvRL(train_data)\n",
        "            state = env.reset()\n",
        "\n",
        "            while not done:\n",
        "                action = agent.choose_action(state)\n",
        "                next_state, reward, done, _ = env.step(action)\n",
        "                agent.update(state, action, reward, next_state)\n",
        "                state = next_state\n",
        "\n",
        "            best_action = np.argmax(agent.q_table.sum(axis=0))\n",
        "            trader_classes[0].fundamental_value = 140 + best_action * 10\n",
        "            trader_classes[1].trend_length = 3 + best_action * 2\n",
        "\n",
        "        # Generate synthetic data on the train set\n",
        "        synthetic_data = generate_synthetic_data(trader_classes, train_data)\n",
        "\n",
        "        # Adjust the synthetic data to match the test set length\n",
        "        synthetic_data = synthetic_data.iloc[:len(test_data)].reset_index(drop=True)\n",
        "\n",
        "        # Evaluate the model on the test set\n",
        "        mse = distance_function(test_data, synthetic_data)\n",
        "        fold_mse.append(mse)\n",
        "\n",
        "    return fold_mse  # Return the list of MSE values for each fold\n",
        "\n",
        "def cross_validate(trader_classes, real_data, method_name, best_params, n_splits=5):\n",
        "    # K-Fold Cross-Validation setup\n",
        "    kf = KFold(n_splits=n_splits)\n",
        "    fold_mse = []\n",
        "\n",
        "    for train_index, test_index in kf.split(real_data):\n",
        "        # Split data into train and test sets\n",
        "        train_data, test_data = real_data.iloc[train_index].reset_index(drop=True), real_data.iloc[test_index].reset_index(drop=True)\n",
        "\n",
        "        # Set best parameters for the traders\n",
        "        fundamental_value, sensitivity, trend_length = best_params\n",
        "        trader_classes[0].fundamental_value = fundamental_value\n",
        "        trader_classes[0].sensitivity = sensitivity\n",
        "        trader_classes[1].trend_length = trend_length\n",
        "\n",
        "        # Generate synthetic data on the train set\n",
        "        synthetic_data = generate_synthetic_data(trader_classes, train_data)\n",
        "\n",
        "        # Adjust the synthetic data to match the test set length\n",
        "        synthetic_data = synthetic_data.iloc[:len(test_data)].reset_index(drop=True)\n",
        "\n",
        "        # Evaluate the model on the test set\n",
        "        mse = distance_function(test_data, synthetic_data)\n",
        "        fold_mse.append(mse)\n",
        "\n",
        "    return fold_mse  # Return list of MSE values\n",
        "\n",
        "# Dictionary to store MSE values for each method across folds\n",
        "results = {}\n",
        "\n",
        "# Cross-validation calls (ensure all methods return a list of MSE values)\n",
        "results['Grid Search'] = cross_validate(trader_classes, real_data, \"Grid Search\", grid_best_params)\n",
        "results['Random Search'] = cross_validate(trader_classes, real_data, \"Random Search\", random_best_params)\n",
        "results['Bayesian Optimisation'] = cross_validate(trader_classes, real_data, \"Bayesian Optimisation\", bayesian_best_params)\n",
        "results['Greedy Search'] = greedy_search_with_plot(trader_classes, real_data)\n",
        "results['Reinforcement Learning'] = train_and_plot_rl(trader_classes, agent, real_data, \"Reinforcement Learning\")\n",
        "\n",
        "print(f\"results: {results}\")\n",
        "\n",
        "mse_values = []\n",
        "methods_labels = []\n",
        "for method, mse_list in results.items():\n",
        "    mse_values.extend(mse_list)  # Collect all MSE values\n",
        "    methods_labels.extend([method] * len(mse_list))  # Label them by method\n",
        "\n",
        "# Create box plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x=methods_labels, y=mse_values)\n",
        "plt.ylabel('Mean Squared Error (MSE)')\n",
        "plt.title('Box Plot of MSE Across Folds for Each Optimisation Method')\n",
        "plt.grid(axis='y')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_RMmOQkWMfB8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}